---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 05-maxent-simple.md in _episodes_rmd/
source: Rmd
title: "Maxent model - test run"
teaching: 10
exercises: 5
questions:
- "How to re-format data for Maxent"
objectives:
- "format data input for Maxent"
- "simple run"
keypoints:
- "111111"
- "22222"
---



## 5 Maxent model - test run  

#### 5.0 prepare occ & raster 

~~~
library("raster")

if(!file.exists("data/occ_raw.rdata")){
  occ_raw <- gbif(genus="Dasypus",species="novemcinctus",download=TRUE) 
  save(occ_raw,file = "data/occ_raw.rdata")
}else{
  load("data/occ_raw.rdata")
}
occ_clean <- subset(occ_raw,(!is.na(lat))&(!is.na(lon))) 
occ_unique <- occ_clean[!duplicated( occ_clean[c("lat","lon")]  ),]
occ_unique_specimen <- subset(occ_unique, basisOfRecord=="PRESERVED_SPECIMEN")
occ_final <- subset(occ_unique_specimen, year>=1950 & year <=2000)
coordinates(occ_final) <- ~ lon + lat
myCRS1 <- CRS("+init=epsg:4326") # WGS 84
crs(occ_final) <- myCRS1

if( !file.exists( paste0("data/bioclim/bio_10m_bil.zip")   )){
  utils::download.file(url="http://biogeo.ucdavis.edu/data/climate/worldclim/1_4/grid/cur/bio_10m_bil.zip",
                       destfile="data/bioclim/bio_10m_bil.zip"   ) 
  utils::unzip("data/bioclim/bio_10m_bil.zip",exdir="data/bioclim") 
}
~~~
{: .language-r}


#### 5.1 format data input for Maxent
The data input can either be **spatial (i.e. spatial points + rasters)** or ***tabular (data frame)**.   
Here is an example of using spatial data:

~~~
clim_list <- list.files("data/bioclim/",pattern=".bil$",full.names = T)
clim <- raster::stack(clim_list) 

cat(class(clim),"  ",  class(occ_final))
~~~
{: .language-r}



~~~
RasterStack    SpatialPointsDataFrame
~~~
{: .output}



~~~
m0 <- maxent(x=clim,p=occ_final)
~~~
{: .language-r}



~~~
Error in maxent(x = clim, p = occ_final): could not find function "maxent"
~~~
{: .error}

However, using spatial data input will make the model less under control. So if you want more control of the modeling process, it is recommended to prepare data in a tabular format. The ideal format is as following:  
![]({{ page.root }}/fig/maxentinput.png). 

Here, we extract environmental conditions for occurrences (training, and testing) and background points, and merge them by row.

~~~
set.seed(1) 
bg <- sampleRandom(x=clim_mask,
                   size=10000,
                   na.rm=T, #removes the 'Not Applicable' points  
                   sp=T) # return spatial points 
~~~
{: .language-r}



~~~
Error in sampleRandom(x = clim_mask, size = 10000, na.rm = T, sp = T): object 'clim_mask' not found
~~~
{: .error}



~~~
set.seed(1) 

# randomly select 50% for training
selected <- sample(  1:nrow(occ_final),  nrow(occ_final)*0.5)

occ_train <- occ_final[selected,] # this is the selection to be used for model training
occ_test <- occ_final[-selected,] # this is the opposite of the selection which will be used for model testing


# extracting env conditions for training occ from the raster stack;
# a data frame is returned (i.e multiple columns)
env_occ_train <- extract(clim,occ_train)

# env conditions for testing occ
env_occ_test <- extract(clim,occ_test)

# extracting env conditions for background
env_bg <- extract(clim,bg)  
~~~
{: .language-r}



~~~
Error in extract(clim, bg): object 'bg' not found
~~~
{: .error}



~~~
#combine the conditions by row
myPredictors <- rbind(env_occ_train,env_bg)
~~~
{: .language-r}



~~~
Error in rbind(env_occ_train, env_bg): object 'env_bg' not found
~~~
{: .error}



~~~
# change matrix to dataframe
myPredictors <- as.data.frame(myPredictors)
~~~
{: .language-r}



~~~
Error in as.data.frame(myPredictors): object 'myPredictors' not found
~~~
{: .error}



~~~
head(myPredictors)
~~~
{: .language-r}



~~~
Error in head(myPredictors): object 'myPredictors' not found
~~~
{: .error}

Maxent reads a **1** as **presence** and **0** as **background**. Thus, we need to assign a **1** to the training environmental conditions and a **0** for the background.We create a set of rows with the same number as the training and testing data, and put the value of "1" for each cell and a "0" for background. We combine the "1"s and "0"s into a vector.


~~~
# repeat the number 1 as many times as the number of rows in p, 
# and repeat 0 for the rows of background points
myResponse <- c(rep(1,nrow(env_occ_train)),
                rep(0,nrow(env_bg))) 
~~~
{: .language-r}



~~~
Error in nrow(env_bg): object 'env_bg' not found
~~~
{: .error}



~~~
# (rep(1,nrow(p)) creating the number of rows as the p data set to 
# have the number '1' as the indicator for presence; rep(0,nrow(a)) 
# creating the number of rows as the a data set to have the number
# '0' as the indicator for absence; the c combines these ones and 
# zeros into a new vector that can be added to the Maxent table data
# frame with the environmental attributes of the presence and absence locations

maxent(x=myPredictors,p=myResponse)
~~~
{: .language-r}



~~~
Error in maxent(x = myPredictors, p = myResponse): could not find function "maxent"
~~~
{: .error}




##3 Maxent models
###3.1 Simple implementation

#####Thread 17

~~~
# use the following code to train Maxent with spatial data
# mod <- maxent(x=clim,p=occ_train)

# to train Maxent with tabular data
mod <- dismo::maxent(x=pder, ## env conditions
              p=pa,   ## 1:presence or 0:absence
              path=paste0(getwd(),"/output/maxent_outputs"), ## folder for maxent output; 
              # if we do not specify a folder R will put the results in a temp file, 
              # and it gets messy to read those. . .
              args=c("responsecurves") ## parameter specification
              )
~~~
{: .language-r}



~~~
Error in dismo::maxent(x = pder, p = pa, path = paste0(getwd(), "/output/maxent_outputs"), : object 'pder' not found
~~~
{: .error}



~~~
# the maxent function runs a model in the default settings. To change these parameters,
# you have to tell it what you want...i.e. response curves or the type of features

# view the maxent model in a html brower
mod
~~~
{: .language-r}



~~~
Error in eval(expr, envir, enclos): object 'mod' not found
~~~
{: .error}



~~~
# view detailed results
# mod@results
~~~
{: .language-r}

###3.2 Predict function
Running Maxent in R will not automatically make a projection to the data layers, unless you specify this using the parameter *projectionlayers*. However, we could make projections (to dataframes or raster layers) post hoc using the *predict* function.

#####Thread 18

~~~
# example 1, project to study area [raster]
class(studyArea)
~~~
{: .language-r}



~~~
Error in eval(expr, envir, enclos): object 'studyArea' not found
~~~
{: .error}



~~~
ped1 <- predict(mod,studyArea) # studyArea is the clipped rasters 
~~~
{: .language-r}



~~~
Error in predict(mod, studyArea): object 'mod' not found
~~~
{: .error}



~~~
plot(ped1) # plot the continuous prediction
~~~
{: .language-r}



~~~
Error in plot(ped1): object 'ped1' not found
~~~
{: .error}



~~~
# example 2, project to the world
#ped2 <- predict(mod,clim)
#plot(ped2)

# example 3, project to a dataframe (training occurrences) [dataframes]. This returns the predicion value assocaited with a set of condions. In this example, we use the training condition to extract a prediction for each point.
head(p)
~~~
{: .language-r}



~~~
Error in head(p): object 'p' not found
~~~
{: .error}



~~~
ped3 <- predict(mod,p)
~~~
{: .language-r}



~~~
Error in predict(mod, p): object 'mod' not found
~~~
{: .error}



~~~
head(ped3)
~~~
{: .language-r}



~~~
Error in head(ped3): object 'ped3' not found
~~~
{: .error}



~~~
hist(ped3)# creates a histogram of the prediction
~~~
{: .language-r}



~~~
Error in hist(ped3): object 'ped3' not found
~~~
{: .error}



~~~
print(p[1:2,])
~~~
{: .language-r}



~~~
Error in print(p[1:2, ]): object 'p' not found
~~~
{: .error}



~~~
predict(mod,p[1:2,])
~~~
{: .language-r}



~~~
Error in predict(mod, p[1:2, ]): object 'mod' not found
~~~
{: .error}

###3.3 Model evaluation
To evaluate models, we use the *evaluate* function from the "dismo" package. Evaluation indices include AUC, TSS, Sensitivity, Specificity, etc.

#####Thread 19

~~~
# Model evaluation, where p & a are dataframes (training presence and background points)

# Evaluate model with training data
mod_eval_train <- dismo::evaluate(p=p,a=a,model=mod) 
~~~
{: .language-r}



~~~
Error in dismo::evaluate(p = p, a = a, model = mod): object 'p' not found
~~~
{: .error}



~~~
print(mod_eval_train)
~~~
{: .language-r}



~~~
Error in print(mod_eval_train): object 'mod_eval_train' not found
~~~
{: .error}



~~~
# Evaluate model with testing data
mod_eval_test <- dismo::evaluate(p=p_test,a=a,model=mod)  
~~~
{: .language-r}



~~~
Error in dismo::evaluate(p = p_test, a = a, model = mod): object 'p_test' not found
~~~
{: .error}



~~~
print(mod_eval_test) 
~~~
{: .language-r}



~~~
Error in print(mod_eval_test): object 'mod_eval_test' not found
~~~
{: .error}



~~~
# training AUC may be higher than testing AUC
~~~
{: .language-r}

To threshold our continuous predictions of suitability into binary predictions we use the threshold function of the "dismo" package. To plot the binary prediction, we plot the predictions that are larger than the threshold.  

#####Thread 20

~~~
# calculate thresholds of models
thd1 <- threshold(mod_eval_train,stat="no_omission") # 0% omission rate 
~~~
{: .language-r}



~~~
Error in threshold(mod_eval_train, stat = "no_omission"): could not find function "threshold"
~~~
{: .error}



~~~
thd2 <- threshold(mod_eval_train,stat="spec_sens") # highest TSS
~~~
{: .language-r}



~~~
Error in threshold(mod_eval_train, stat = "spec_sens"): could not find function "threshold"
~~~
{: .error}



~~~
thd3 <- threshold(mod_eval_train,stat="sensitivity",sensitivity=0.9) # 10% omission rate, i.e. sensitivity=0.9
~~~
{: .language-r}



~~~
Error in threshold(mod_eval_train, stat = "sensitivity", sensitivity = 0.9): could not find function "threshold"
~~~
{: .error}



~~~
thd4 <- threshold(mod_eval_train,stat="sensitivity",sensitivity=0.95) # 10% omission rate, i.e. sensitivity=0.9
~~~
{: .language-r}



~~~
Error in threshold(mod_eval_train, stat = "sensitivity", sensitivity = 0.95): could not find function "threshold"
~~~
{: .error}



~~~
# thresholds are parameters that must be specified you find the list in the help document for the threshold function in the dismo package

# plotting points that are higher than the previously calculated thresholded value
plot(ped1>=thd1) 
~~~
{: .language-r}



~~~
Error in plot(ped1 >= thd1): object 'ped1' not found
~~~
{: .error}



> ## Challenge: use your occurrences to cut raster layers 
> load occurrences & raster layers   
> build a `600,000 meter` buffer around occurrences    
> `mask` raster by the buffer of occurrences  
> plot the masked raster  
> > ## Solution
> > 
> > ~~~
> > library("raster")
> > 
> > if(!file.exists("data/occ_raw.rdata")){
> >   occ_raw <- gbif(genus="Dasypus",species="novemcinctus",download=TRUE) 
> >   save(occ_raw,file = "data/occ_raw.rdata")
> > }else{
> >   load("data/occ_raw.rdata")
> > }
> > occ_clean <- subset(occ_raw,(!is.na(lat))&(!is.na(lon))) 
> > occ_unique <- occ_clean[!duplicated( occ_clean[c("lat","lon")]  ),]
> > occ_unique_specimen <- subset(occ_unique, basisOfRecord=="PRESERVED_SPECIMEN")
> > occ_final <- subset(occ_unique_specimen, year>=1950 & year <=2000)
> > coordinates(occ_final) <- ~ lon + lat
> > myCRS1 <- CRS("+init=epsg:4326") # WGS 84
> > crs(occ_final) <- myCRS1
> > 
> > if( !file.exists( paste0("data/bioclim/bio_10m_bil.zip")   )){
> >   utils::download.file(url="http://biogeo.ucdavis.edu/data/climate/worldclim/1_4/grid/cur/bio_10m_bil.zip",
> >                        destfile="data/bioclim/bio_10m_bil.zip"   ) 
> >   utils::unzip("data/bioclim/bio_10m_bil.zip",exdir="data/bioclim") 
> > }
> > 
> > bio1 <- raster("data/bioclim/bio1.bil")
> > 
> > occ_buffer <- buffer(occ_final,width=6*10^5) #unit is meter
> > bio1_mask <- mask(bio1, occ_buffer)
> > 
> > plot(bio1_mask)
> > plot(occ_buffer,add=T)
> > plot(occ_final,add=T,col="blue")
> > ~~~
> > {: .language-r}
> {: .solution}
{: .challenge}
{% include links.md %}
