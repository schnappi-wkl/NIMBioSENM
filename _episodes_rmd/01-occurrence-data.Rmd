---
source: Rmd
title: "Occurrence data"
teaching: 10
exercises: 5
questions:
- "11111111111"
objectives:
- "Download occurrence data through API."
- "Filter occurrance data."
keypoints:
- "111111"
- "22222"
---

```{r load pk,message=FALSE,warning=FALSE,echo=FALSE}
source("../bin/chunk-options.R")

# not for shown
library("raster")
library("dismo")
library("rgeos")
library("rgdal")
library("sp")
library("ENMeval")
library("ggplot2")

if(file.exists("data/occ_raw.rdata")){
  load("data/occ_raw.rdata")
}else{
occ_raw <- gbif(genus="Dasypus",species="novemcinctus",download=TRUE) # the default is to download all
save(occ_raw,file = "data/occ_raw.rdata")
  write.csv("data/occ_raw.csv")
}
```

## 2 Occurrence data  
#### 2.1 Download occurrence data  

(fix me) add a decription about biodiversity databases; a figure about GBIF; a list of databases; what is api;  

`gbif()` is a function in `dismo` package, which can directly download occurrences through GBIF api; here we query the number of records of the nine-banded armadillo, **without downloading**  
```{r download1, message=FALSE, warning=FALSE,eval=TRUE}
gbif(genus="Dasypus",species="novemcinctus",download=FALSE)
```

by setting `download=TRUE`, we can download all records  
```{r download2, message=FALSE, warning=FALSE,eval=FALSE}
occ_raw <- gbif(genus="Dasypus",species="novemcinctus",download=TRUE) 

# to view the first few records the occurrence dataset use:
#head( occ_raw )
```


#### 2.2 List of biodiversity databases and their R package.  

Table 1. List of biodiversity databases and their R package. 

|Database  | R package |  
|---  | --- |  
| BIEN | [BIEN](https://cran.r-project.org/web/packages/BIEN/vignettes/BIEN_tutorial.html)|  
 BISON | [rbison](https://github.com/ropensci/rbison)
 eBird | [rebird](http://ebird.org/content/ebird/)
 GBIF | [rgbif](https://github.com/ropensci/rgbif)
 iNaturalist | [rinat](https://github.com/ropensci/rinat)
 VertNet | [rvertnet](https://github.com/ropensci/rvertnet)
 iDigBio  | [ridigbio](https://www.idigbio.org/)  
   
The great thing is, you could query many databases at one time using [spocc](https://github.com/ropensci/spocc) package, developed by [*rOpenSci*](https://ropensci.org/packages/)

#### 2.3 occurrence data in Darwin Core  
Take a look at the columns of the GBIF occurrences.
```{r columns, message=FALSE, warning=FALSE}
names(occ_raw)
```
The meaning of those columns/terms are defined by Darwin Core. Refer to [Darwin Core quick reference guide](https://dwc.tdwg.org/terms/) for more information.  

A few columns to highlight:  
* `basisOfRecord`  
  * The specific nature of the data record.  
  * PreservedSpecimen, FossilSpecimen, LivingSpecimen, MaterialSample, Event, HumanObservation, MachineObservation, Taxon, Occurrence  
  
* `year`  
  * The four-digit year in which the Event occurred, according to the Common Era Calendar.

* `lat` and `lon` (or `decimalLongitude`,`decimalLatitude` in Darwin Core)  
  *The geographic longitude/latitude of the geographic center of a Location. Positive values are  east of the Greenwich Meridian/north of the Equator, negative values are west/south of it. Legal values lie between [-180 180] / [-90 90], inclusive.

#### 2.4 Clean occurrence data
Since some of our records do not have appropriate coordinates and some have missing locational data, we need to remove them from our dataset. To do this, we created a new dataset named “occ_clean”, which is a subset of the “occ_raw” dataset where records with missing latitude and/or longitude are removed.  
```{r clean_data1}
# here we remove erroneous coordinates, where either the latitude or longitude is missing
occ_clean <- subset(occ_raw,(!is.na(lat))&(!is.na(lon))) 
#  "!" means the opposite logic value

#Show the number of records that are removed from the dataset.  
cat(nrow(occ_raw)-nrow(occ_clean), "records are removed")
```  

Remove duplicated data based on latitude and longitude  
```{r clean_data2}
dups <- duplicated( occ_clean[c("lat","lon")]  )
occ_unique <- occ_clean[!dups,]
cat(nrow(occ_clean)-nrow(occ_unique), "records are removed")
```
  

show the frequency table of "basisOfRecord"
```{r clean_data3}
table(occ_unique$basisOfRecord)
```
  

only keep record that are associted with a specimen
```{r clean_data4}
occ_unique_specimen <- subset(occ_unique, basisOfRecord=="PRESERVED_SPECIMEN")
cat(nrow(occ_unique_specimen), "out of ", nrow(occ_unique), "records are specimen")
```

show the histogram of "year"
```{r clean_data5,fig.height = 6, fig.width = 6, fig.align = "center"}
hist(occ_unique_specimen$year)
#ggplot2()
```


to filter the species records by year, in this example 1950 to 2000:
```{r clean_data6}
occ_unique_specimen_present <- subset(occ_unique_specimen, year>=1950 & year <=2000)
```

show a quick summary of years in the data
```{r clean_data7}
summary(occ_unique_specimen_present$year)
```





> ## Challenge: Download occurrences from GBIF and filter data
> select your favorite species  
> only keep `specimen` records  
> only keep records that are collected between `2000 & 2018`  
> only keep records that have `valid longitude & latitude`  
> > ## Solution
> > ```{r check_setups, echo=TRUE,eval=FALSE}
> > # download 
> > myocc <- gbif(genus="Dasypus",species="novemcinctus",download=TRUE) 
> >  
> > # filter 
> > myocc_final <- subset(myocc,basisOfRecord=="PRESERVED_SPECIMEN" &
> >                             year >= 2000 & year <= 2018 &
> >                             !is.na(lat) & !is.na(lon)    )
> > 
> > # show number of records that are removed 
> > nrow(myocc) - nrow(myocc_final)                          
> > ```
> {: .solution}
{: .challenge}
{% include links.md %}
