---
source: Rmd
title: "Maxent model - test run"
teaching: 10
exercises: 5
questions:
- "How to re-format data for Maxent"
objectives:
- "format data input for Maxent"
- "simple run"
keypoints:
- "111111"
- "22222"
---

```{r load pk,message=FALSE,warning=FALSE,echo=FALSE}
source("../bin/chunk-options.R")
```

## 5 Maxent model - test run  

#### 5.0 prepare occ & raster 
```{r occraster1, message=FALSE, warning=FALSE}
library("raster")

if(!file.exists("data/occ_raw.rdata")){
  occ_raw <- gbif(genus="Dasypus",species="novemcinctus",download=TRUE) 
  save(occ_raw,file = "data/occ_raw.rdata")
}else{
  load("data/occ_raw.rdata")
}
occ_clean <- subset(occ_raw,(!is.na(lat))&(!is.na(lon))) 
occ_unique <- occ_clean[!duplicated( occ_clean[c("lat","lon")]  ),]
occ_unique_specimen <- subset(occ_unique, basisOfRecord=="PRESERVED_SPECIMEN")
occ_final <- subset(occ_unique_specimen, year>=1950 & year <=2000)
coordinates(occ_final) <- ~ lon + lat
myCRS1 <- CRS("+init=epsg:4326") # WGS 84
crs(occ_final) <- myCRS1

if( !file.exists( paste0("data/bioclim/bio_10m_bil.zip")   )){
  utils::download.file(url="http://biogeo.ucdavis.edu/data/climate/worldclim/1_4/grid/cur/bio_10m_bil.zip",
                       destfile="data/bioclim/bio_10m_bil.zip"   ) 
  utils::unzip("data/bioclim/bio_10m_bil.zip",exdir="data/bioclim") 
}

```


#### 5.1 format data input for Maxent
The data input can either be **spatial (i.e. spatial points + rasters)** or ***tabular (data frame)**.   
Here is an example of using spatial data:
```{r prepare_data_for_maxent2,message=FALSE}
clim_list <- list.files("data/bioclim/",pattern=".bil$",full.names = T)
clim <- raster::stack(clim_list) 

cat(class(clim),"  ",  class(occ_final))

m0 <- maxent(x=clim,p=occ_final)
```

However, using spatial data input will make the model less under control. So if you want more control of the modeling process, it is recommended to prepare data in a tabular format. The ideal format is as following:  
![]({{ page.root }}/fig/maxentinput.png). 

Here, we extract environmental conditions for occurrences (training, and testing) and background points, and merge them by row.
```{r prepare_data_for_maxent3,message=FALSE}

set.seed(1) 
bg <- sampleRandom(x=clim_mask,
                   size=10000,
                   na.rm=T, #removes the 'Not Applicable' points  
                   sp=T) # return spatial points 



set.seed(1) 

# randomly select 50% for training
selected <- sample(  1:nrow(occ_final),  nrow(occ_final)*0.5)

occ_train <- occ_final[selected,] # this is the selection to be used for model training
occ_test <- occ_final[-selected,] # this is the opposite of the selection which will be used for model testing


# extracting env conditions for training occ from the raster stack;
# a data frame is returned (i.e multiple columns)
env_occ_train <- extract(clim,occ_train)

# env conditions for testing occ
env_occ_test <- extract(clim,occ_test)

# extracting env conditions for background
env_bg <- extract(clim,bg)  

#combine the conditions by row
myPredictors <- rbind(env_occ_train,env_bg)

# change matrix to dataframe
myPredictors <- as.data.frame(myPredictors)
head(myPredictors)
```

Maxent reads a **1** as **presence** and **0** as **background**. Thus, we need to assign a **1** to the training environmental conditions and a **0** for the background.We create a set of rows with the same number as the training and testing data, and put the value of "1" for each cell and a "0" for background. We combine the "1"s and "0"s into a vector.

```{r prepare_data_for_maxent4,message=FALSE}
# repeat the number 1 as many times as the number of rows in p, 
# and repeat 0 for the rows of background points
myResponse <- c(rep(1,nrow(env_occ_train)),
                rep(0,nrow(env_bg))) 

# (rep(1,nrow(p)) creating the number of rows as the p data set to 
# have the number '1' as the indicator for presence; rep(0,nrow(a)) 
# creating the number of rows as the a data set to have the number
# '0' as the indicator for absence; the c combines these ones and 
# zeros into a new vector that can be added to the Maxent table data
# frame with the environmental attributes of the presence and absence locations

maxent(x=myPredictors,p=myResponse)

```




##3 Maxent models
###3.1 Simple implementation

#####Thread 17
```{r simple_maxent_model}
# use the following code to train Maxent with spatial data
# mod <- maxent(x=clim,p=occ_train)

# to train Maxent with tabular data
mod <- dismo::maxent(x=pder, ## env conditions
              p=pa,   ## 1:presence or 0:absence
              path=paste0(getwd(),"/output/maxent_outputs"), ## folder for maxent output; 
              # if we do not specify a folder R will put the results in a temp file, 
              # and it gets messy to read those. . .
              args=c("responsecurves") ## parameter specification
              )
# the maxent function runs a model in the default settings. To change these parameters,
# you have to tell it what you want...i.e. response curves or the type of features

# view the maxent model in a html brower
mod

# view detailed results
# mod@results
```

###3.2 Predict function
Running Maxent in R will not automatically make a projection to the data layers, unless you specify this using the parameter *projectionlayers*. However, we could make projections (to dataframes or raster layers) post hoc using the *predict* function.

#####Thread 18
```{r predict}

# example 1, project to study area [raster]
class(studyArea)
ped1 <- predict(mod,studyArea) # studyArea is the clipped rasters 
plot(ped1) # plot the continuous prediction

# example 2, project to the world
#ped2 <- predict(mod,clim)
#plot(ped2)

# example 3, project to a dataframe (training occurrences) [dataframes]. This returns the predicion value assocaited with a set of condions. In this example, we use the training condition to extract a prediction for each point.
head(p)
ped3 <- predict(mod,p)
head(ped3)
hist(ped3)# creates a histogram of the prediction

print(p[1:2,])
predict(mod,p[1:2,])

```

###3.3 Model evaluation
To evaluate models, we use the *evaluate* function from the "dismo" package. Evaluation indices include AUC, TSS, Sensitivity, Specificity, etc.

#####Thread 19
```{r model_evaluation1}
# Model evaluation, where p & a are dataframes (training presence and background points)

# Evaluate model with training data
mod_eval_train <- dismo::evaluate(p=p,a=a,model=mod) 
print(mod_eval_train)

# Evaluate model with testing data
mod_eval_test <- dismo::evaluate(p=p_test,a=a,model=mod)  
print(mod_eval_test) 

# training AUC may be higher than testing AUC
```			

To threshold our continuous predictions of suitability into binary predictions we use the threshold function of the "dismo" package. To plot the binary prediction, we plot the predictions that are larger than the threshold.  

#####Thread 20
```{r model_evaluation2}

# calculate thresholds of models
thd1 <- threshold(mod_eval_train,stat="no_omission") # 0% omission rate 
thd2 <- threshold(mod_eval_train,stat="spec_sens") # highest TSS
thd3 <- threshold(mod_eval_train,stat="sensitivity",sensitivity=0.9) # 10% omission rate, i.e. sensitivity=0.9
thd4 <- threshold(mod_eval_train,stat="sensitivity",sensitivity=0.95) # 10% omission rate, i.e. sensitivity=0.9

# thresholds are parameters that must be specified you find the list in the help document for the threshold function in the dismo package

# plotting points that are higher than the previously calculated thresholded value
plot(ped1>=thd1) 
```



> ## Challenge: use your occurrences to cut raster layers 
> load occurrences & raster layers   
> build a `600,000 meter` buffer around occurrences    
> `mask` raster by the buffer of occurrences  
> plot the masked raster  
> > ## Solution
> > ```{r, echo=TRUE,eval=FALSE}
> > library("raster")
> > 
> > if(!file.exists("data/occ_raw.rdata")){
> >   occ_raw <- gbif(genus="Dasypus",species="novemcinctus",download=TRUE) 
> >   save(occ_raw,file = "data/occ_raw.rdata")
> > }else{
> >   load("data/occ_raw.rdata")
> > }
> > occ_clean <- subset(occ_raw,(!is.na(lat))&(!is.na(lon))) 
> > occ_unique <- occ_clean[!duplicated( occ_clean[c("lat","lon")]  ),]
> > occ_unique_specimen <- subset(occ_unique, basisOfRecord=="PRESERVED_SPECIMEN")
> > occ_final <- subset(occ_unique_specimen, year>=1950 & year <=2000)
> > coordinates(occ_final) <- ~ lon + lat
> > myCRS1 <- CRS("+init=epsg:4326") # WGS 84
> > crs(occ_final) <- myCRS1
> > 
> > if( !file.exists( paste0("data/bioclim/bio_10m_bil.zip")   )){
> >   utils::download.file(url="http://biogeo.ucdavis.edu/data/climate/worldclim/1_4/grid/cur/bio_10m_bil.zip",
> >                        destfile="data/bioclim/bio_10m_bil.zip"   ) 
> >   utils::unzip("data/bioclim/bio_10m_bil.zip",exdir="data/bioclim") 
> > }
> > 
> > bio1 <- raster("data/bioclim/bio1.bil")
> > 
> > occ_buffer <- buffer(occ_final,width=6*10^5) #unit is meter
> > bio1_mask <- mask(bio1, occ_buffer)
> > 
> > plot(bio1_mask)
> > plot(occ_buffer,add=T)
> > plot(occ_final,add=T,col="blue")
> > ```
> {: .solution}
{: .challenge}
{% include links.md %}
